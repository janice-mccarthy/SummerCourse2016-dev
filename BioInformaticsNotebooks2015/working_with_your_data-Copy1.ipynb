{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Getting started\n",
    "To be sure that we don't fill up our VMs with the full datasets, we will work on our scratch drives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[34;42mcombined\u001b[0m/                       groups_EG_combined_R2.fastq.gz\r\n",
      "dryrun_combined_I1.fastq.gz     groups_KNP_combined_I1.fastq.gz\r\n",
      "dryrun_combined_R1.fastq.gz     groups_KNP_combined_R1.fastq.gz\r\n",
      "dryrun_combined_R2.fastq.gz     groups_KNP_combined_R2.fastq.gz\r\n",
      "groups_EG_combined_I1.fastq.gz  \u001b[34;42mngs2016_test\u001b[0m/\r\n",
      "groups_EG_combined_R1.fastq.gz  raw_data.md5sum\r\n"
     ]
    }
   ],
   "source": [
    "ls ../../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mkdir -p ~/data/analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/data/analysis\n"
     ]
    }
   ],
   "source": [
    "cd ~/data/analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Data\n",
    "All of the data is in `/mnt/nfs/ngsworkshop/colab-sbx-16/raw_data/`.  The sequencing is being done in pools of 18 (pool 1) or 12 (pool 2) samples.  In order to get approzimately similar coverage of all samples, pool 1 is being sequenced 3 times, and pool 2 is being sequenced twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a link to the raw data to save ourselves some typing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Concatenating Run Files\n",
    "If you are interested in run-specific batch effect, you would want to treat samples from different sequencing runs as separate technical replicates and compare them.  Otherwise it is going to be simpler to just combine comparable files from different runs (e.g. R1 files together, R2 files together, and I1 files together).  A simple way to do this is with `zcat`, `gzip`, a pipe, and a redirect:\n",
    "\n",
    "`zcat pool1_run1_R1.fastq.gz pool1_run2_R1.fastq.gz | gzip > pool1_R1.fastq.gz`\n",
    "\n",
    "Just be absolutely certain that you do not switch the order between reads (i.e. run1, then run2 for R1; run2, then run1 for R2): remember that reads need to be kept in the same order across files.  \n",
    "\n",
    "Details on how to do this are below.  First, let's make a directory for the combined files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[34;42manalysis\u001b[0m/                       groups_EG_combined_R2.fastq.gz\r\n",
      "\u001b[34;42mcombined\u001b[0m/                       groups_KNP_combined_I1.fastq.gz\r\n",
      "dryrun_combined_I1.fastq.gz     groups_KNP_combined_R1.fastq.gz\r\n",
      "dryrun_combined_R1.fastq.gz     groups_KNP_combined_R2.fastq.gz\r\n",
      "dryrun_combined_R2.fastq.gz     \u001b[34;42mngs2016_test\u001b[0m/\r\n",
      "groups_EG_combined_I1.fastq.gz  raw_data.md5sum\r\n",
      "groups_EG_combined_R1.fastq.gz\r\n"
     ]
    }
   ],
   "source": [
    "ls ~/data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's figure out a what files we want to combine.  We will work with Pool 1 first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ls: cannot access /home/jovyan/data/groups_KNP_run?/????1_S1_L001_??_001.fastq.gz: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls ~/data/groups_KNP_run?/????1_S1_L001_??_001.fastq.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we will want to combine the R1 files into one, the R2 files into one, and the I1 files into one, so we will use a for loop to do each group of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "for READ in I1 R1 R2 \n",
    "    do\n",
    "        zcat ~/raw_data/groups_KNP_run?/????1_S1_L001_${READ}_001.fastq.gz | \\\n",
    "            gzip > ~/raw_data/combined/groups_KNP_combined_${READ}.fastq.gz\n",
    "    done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will work with Pool 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls ~/raw_data/groups_EG_run?/POOL2_S1_L001_I1_001.fastq.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "for READ in I1 R1 R2 \n",
    "    do\n",
    "        zcat ~/raw_data/groups_EG_run?/POOL2_S1_L001_${READ}_001.fastq.gz | \\\n",
    "            gzip > ~/raw_data/combined/groups_EG_combined_${READ}.fastq.gz\n",
    "    done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Demultiplexing\n",
    "Unless we are interested in analyzing the sequencing runs separately, it is less work to demultiplex the runs after concatenating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using fastq-multx to demultiplex\n",
    "`fastq-multx` comes from ea-utils, the same package that provides `fastq-mcf`.  It is pretty straightforward to use.  Since we have barcodes in a separate file, we are contrained in how we run it:\n",
    "\n",
    "* -B BARCODE_FILE : a list of known barcodes, and the associated sample names\n",
    "* -o OUTPUT_FILE(s) : fastq-multx will produce a separate file for each barcode (two files when paired-end reads are input).  This option provides a template for naming the output file - the program will fill in the \"%\" with the barcode.\n",
    "* -m : number of mismatches to allow in barcode \n",
    "* -d : minimum edit distance between the best and next best match\n",
    "* -x : don't trim barcodes\n",
    "* I1_FASTQ : the index read FASTQ, which will be used to demultiplex other reads\n",
    "* R1_FASTQ : the R1 raw data to demultiplex\n",
    "* R2_FASTQ : (optional) if data is paired-end, the R2 raw data to demultiplex\n",
    "\n",
    "*Note:* You can ignore the error message \"gzip: stdout: Broken pipe\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/work/BioInformaticsNotebooks2015'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Barcode File: /home/jovyan/work/BioInformaticsNotebooks2015/pool1_barcodes.tab\n",
      "End used: start\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "GROUP=KNP\n",
    "OUTDIR=~/data/${GROUP}_demux\n",
    "mkdir -p $OUTDIR\n",
    "fastq-multx -m1 -d1 -x -B ~/work/BioInformaticsNotebooks2015/pool1_barcodes.tab \\\n",
    "    ~/data/groups_${GROUP}_combined_I1.fastq.gz \\\n",
    "    ~/data/groups_${GROUP}_combined_R1.fastq.gz \\\n",
    "    ~/data/groups_${GROUP}_combined_R2.fastq.gz \\\n",
    "    -o ${OUTDIR}/i1.%.fq.gz ${OUTDIR}/r1.%.fq.gz ${OUTDIR}/r2.%.fq.gz \\\n",
    "    > ${OUTDIR}/demux_summary.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run pool2 - remember to use `pool2_barcodes.tab`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Barcode File: /home/jovyan/work/BioInformaticsNotebooks2015/pool2_barcodes.tab\n",
      "End used: start\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "GROUP=EG\n",
    "OUTDIR=~/data/${GROUP}_demux\n",
    "mkdir -p $OUTDIR\n",
    "fastq-multx -m1 -d1 -x -B ~/work/BioInformaticsNotebooks2015/pool2_barcodes.tab \\\n",
    "    ~/data/groups_${GROUP}_combined_I1.fastq.gz \\\n",
    "    ~/data/groups_${GROUP}_combined_R1.fastq.gz \\\n",
    "    ~/data/groups_${GROUP}_combined_R2.fastq.gz \\\n",
    "    -o ${OUTDIR}/i1.%.fq.gz ${OUTDIR}/r1.%.fq.gz ${OUTDIR}/r2.%.fq.gz \\\n",
    "    > ${OUTDIR}/demux_summary.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when you supply `fastq-multx` with an index read file, it automatically determines what the barcodes are . . . and sometimes it finds some that were not used in any of the libraries.  We will just discard these bogus barcodes.\n",
    "\n",
    "##Next Steps\n",
    "Now we are ready to run our pipeline on the data.  I recommend doing it the same way we did the analysis before - run just one sample, check to be sure it looks OK, then run the rest of the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_neb_adapters.fasta\n",
      "annotation.csv\n",
      "annotation.ipynb\n",
      "annotation_prep.ipynb\n",
      "check_R.R\n",
      "counting.ipynb\n",
      "demux_exploration.ipynb\n",
      "DESeq2-Notebook-from-Matrix.ipynb\n",
      "DESeq2-Notebook.ipynb\n",
      "file_transfer_and_visualization.ipynb\n",
      "indices.csv\n",
      "install_fastq_multx.sh\n",
      "mapping.ipynb\n",
      "neb_19_adapter.fasta\n",
      "parse_gtf.py\n",
      "pool1_barcodes.tab\n",
      "pool2_barcodes.tab\n",
      "preprocessing.ipynb\n",
      "putting_it_together_all_data.ipynb\n",
      "putting_it_together.ipynb\n",
      "revcomp.py\n",
      "testrun_adapters.fasta\n",
      "test_run_counts_OLD\n",
      "update_R_notes.txt\n",
      "update_R.sh\n",
      "working_with_your_data-Copy1.ipynb\n",
      "working_with_your_data.ipynb\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "ls \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ls: cannot access EG_demux: No such file or directory\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
